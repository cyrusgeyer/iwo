{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch \n",
    "from src.utils.iwo import get_basis\n",
    "\n",
    "L = 10\n",
    "W_list = [torch.rand(l - 1, l).to(torch.float64) for l in reversed(range(2, L + 1))]\n",
    "W_list = (\n",
    "    [torch.rand(5, L).to(torch.float64)]\n",
    "    + W_list[5:-2]\n",
    "    + [torch.rand(1, 3).to(torch.float64)]\n",
    ")\n",
    "b_list = get_basis(W_list)\n",
    "\n",
    "# Test orthogonality\n",
    "B = torch.concat(b_list, axis=1)\n",
    "eye = torch.eye(B.size(0), dtype=B.dtype, device=B.device)\n",
    "assert torch.allclose(B.t() @ B, eye, atol=1e-08)\n",
    "\n",
    "# Test that the basis vectors are indeed inside the null space of the next smaller matrix\n",
    "B_flipped = b_list[::-1]  # Re-order from least important to most important\n",
    "for i in range(len(W_list)):\n",
    "    reduction = W_list[i].shape[1] - W_list[i].shape[0]\n",
    "    t = B_flipped[i]\n",
    "    for j in range(i + 1):\n",
    "        t = W_list[j] @ t\n",
    "    # Assert if the the projection is indeed inside the null-space.\n",
    "    assert torch.any(torch.le(t, 1e-6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5, 0.5, 0.5, 0.5]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[0.5] * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_dtype = torch.float64\n",
    "\n",
    "old_dtype = W_list[0].dtype\n",
    "device = W_list[0].device\n",
    "\n",
    "if old_dtype != new_dtype:\n",
    "    W_list = [m.to(new_dtype) for m in W_list]\n",
    "\n",
    "\n",
    "b_list = []\n",
    "W_prod = torch.eye(W_list[0].shape[1], device=device, dtype=new_dtype)\n",
    "\n",
    "for i, W in enumerate(W_list):\n",
    "    W_prod = W @ W_prod\n",
    "    reduction = W.shape[1] - W.shape[0]\n",
    "    T = torch.concat([W_prod.t()] + b_list, axis=1)\n",
    "    Qr, _ = torch.linalg.qr(T, mode=\"complete\")\n",
    "    b_list.append(torch.flip(Qr[:, -reduction:], dims=[1]))\n",
    "\n",
    "T = torch.concat(b_list, axis=1)\n",
    "reduction = T.shape[0] - T.shape[1]\n",
    "Qr, _ = torch.linalg.qr(T, mode=\"complete\")\n",
    "b_list.append(torch.flip(Qr[:, -reduction:], dims=[1]))\n",
    "b_list.reverse()\n",
    "b_list = [b.to(old_dtype) for b in b_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.3438],\n",
       "         [0.2543],\n",
       "         [0.3638],\n",
       "         [0.3072],\n",
       "         [0.2287],\n",
       "         [0.2260],\n",
       "         [0.4675],\n",
       "         [0.2897],\n",
       "         [0.2763],\n",
       "         [0.3289]], dtype=torch.float64),\n",
       " tensor([[-0.3589, -0.5186],\n",
       "         [-0.1743, -0.3852],\n",
       "         [-0.3736,  0.2272],\n",
       "         [-0.1395,  0.3791],\n",
       "         [ 0.0725, -0.2839],\n",
       "         [ 0.4672,  0.1903],\n",
       "         [ 0.1241, -0.0115],\n",
       "         [-0.2950,  0.4221],\n",
       "         [ 0.2918,  0.2035],\n",
       "         [ 0.5202, -0.2254]], dtype=torch.float64),\n",
       " tensor([[-0.2979],\n",
       "         [ 0.3589],\n",
       "         [ 0.2030],\n",
       "         [-0.0258],\n",
       "         [-0.0663],\n",
       "         [-0.5247],\n",
       "         [-0.2214],\n",
       "         [-0.1384],\n",
       "         [ 0.6031],\n",
       "         [ 0.1702]], dtype=torch.float64),\n",
       " tensor([[-0.2443],\n",
       "         [ 0.1451],\n",
       "         [-0.5885],\n",
       "         [ 0.2980],\n",
       "         [ 0.2255],\n",
       "         [-0.3754],\n",
       "         [ 0.4909],\n",
       "         [ 0.1405],\n",
       "         [-0.0365],\n",
       "         [-0.1739]], dtype=torch.float64),\n",
       " tensor([[-0.2124,  0.3430,  0.0309, -0.1719, -0.3774],\n",
       "         [ 0.3260,  0.3174,  0.1199,  0.1225,  0.6086],\n",
       "         [ 0.0105, -0.3879, -0.2586,  0.2465,  0.1034],\n",
       "         [ 0.3791,  0.2442, -0.5193, -0.4033, -0.1312],\n",
       "         [-0.3092, -0.5663, -0.1280, -0.5201,  0.3216],\n",
       "         [-0.0359,  0.2779, -0.0221, -0.0360,  0.4447],\n",
       "         [-0.1728, -0.1008, -0.1142,  0.6400, -0.1147],\n",
       "         [ 0.0384, -0.0879,  0.7579, -0.1673,  0.0194],\n",
       "         [-0.5529,  0.3121,  0.0501, -0.1274, -0.1008],\n",
       "         [ 0.5204, -0.2416,  0.2030, -0.0799, -0.3666]], dtype=torch.float64)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_list[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_list[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_list[3].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1102e-16,  2.1684e-17, -2.0817e-17,  8.6736e-17,  3.7470e-16],\n",
      "        [-1.0755e-16, -9.6494e-18, -7.9364e-17,  1.0582e-16,  2.1511e-16],\n",
      "        [ 5.5511e-17, -2.6888e-17,  1.8735e-16,  3.1225e-17,  3.0531e-16],\n",
      "        [ 2.8103e-16,  2.3202e-17,  1.6306e-16,  0.0000e+00, -6.3317e-17],\n",
      "        [-5.5511e-17, -1.1102e-16,  5.5511e-17,  1.1102e-16,  1.1102e-16]],\n",
      "       dtype=torch.float64)\n",
      "tensor([[ 2.7756e-17],\n",
      "        [ 4.1633e-17],\n",
      "        [ 8.3267e-17],\n",
      "        [-1.3878e-17]], dtype=torch.float64)\n",
      "tensor([[-4.2327e-16],\n",
      "        [ 5.5511e-16],\n",
      "        [-3.6082e-16]], dtype=torch.float64)\n",
      "tensor([[-4.3802e-16, -4.6491e-16]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduction = W_list[0].shape[1] - W_list[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.7756e-17,  3.4694e-17, -1.6653e-16, -2.2204e-16,  5.5511e-17],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_list[0] @ B_flipped[:, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.2204e-16, -1.3323e-15, -5.5511e-17], dtype=torch.float64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_list[2] @ W_list[1] @ W_list[0] @ B_flipped[:, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([18.0246], dtype=torch.float64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_list[4] @ W_list[3] @ W_list[2] @ W_list[1] @ W_list[0] @ B_flipped[:, 9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
